{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Introduction to Computer Vision**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Computer Vision?\n",
    "\n",
    "![cars_example](http://hdgreetings.typepad.com/.a/6a00e54fc3203e883401b7c7a84e63970b-800wi \"Cars Example\")\n",
    "\n",
    "Computer vision is the process that allows for computers to have a high level understanding of information from images or videos. \"High level understanding\" means more than simply the data that makes up an image or video. It means to understand what is going on in the image. Is there a car? Is it facing toward or away from the camera? If it is a video, what is the speed of the car?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing\n",
    "\n",
    "For robomasters, we will primarily be using [OpenCV](https://opencv.org/). OpenCV stands for open source computer vision and it is a great choice for all levels of computer vision applications. It works on almost any platform and has interfaces available for Python, C++, and Java. You may use which ever language you are most comfortable with for robomasters work, but Python will be used for demonstrations and guides.\n",
    "\n",
    "For Python, the easist way to install OpenCV is with `pip`, a package manager for Python. Depending on your setup, you may need to use `pip3` instead. To install OpenCV with `pip` enter the following command:\n",
    "\n",
    "`pip install opencv-python`\n",
    "\n",
    "To check if OpenCV installed, start the Python 3 repl in your terminal, by entering either `python` or `python3`. Then in the repl enter:\n",
    "\n",
    "`import cv2`\n",
    "\n",
    "Next enter:\n",
    "\n",
    "`print(cv2.__version__)`\n",
    "\n",
    "If \"3.X.X\" is printed you have successfully installed OpenCV. Congratulations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In almost all of your OpenCV programs you will need the first two lines to be as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import imutils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We already know that `cv2` refers to the OpenCV library. The second import, called `numpy`, is a scientific computing package."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying an Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying an image with OpenCV is very simple. It requies four basic functions. The first `imread` does exactly what it sounds like. It reads an image located somewhere on your computer. For the first example `image_1.png` will be used. It is located in the same directory as this one. If you want to view the image you can open it within Jupyter Lab by simply double clicking on it in the directory. The cell below demonstrates how to declare an image for use with OpenCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('image_1.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the `type` of `img` is printed, we can see that `img` is in fact simply an `numpy` type called an `ndarray` standing for n-dimensional array. We can then print `img` variable itself and see that is simply a three dimensional array as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [255 255 255]\n",
      "  ...\n",
      "  [255 255 255]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]\n",
      "\n",
      " [[  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  ...\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]\n",
      "  [  0   0   0]]]\n"
     ]
    }
   ],
   "source": [
    "print(type(img))\n",
    "print(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously this is a huge array, so it is not very helpful to print the whole array at once. Instead let's print just a single pixel from the image at point (50,50). For dealing with images, point (0,0) is the upper left corner of the image. The resulting array is of length three and shows the color values for the pixel at that coordinate in BGR (blue, green, red) format. This is what an image is made up of. It is simply multidimensional array of pixel values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 62 148  43]\n"
     ]
    }
   ],
   "source": [
    "print(img[50][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To actually show the image, two more functions are needed. `imshow` shows the image and takes the name of the window and the image (remember an image is just an `ndarray`). The second function isn't as obvious. It is called `waitKey` and it allows you to designate the amount of time you wish for the image to show in milliseconds. In the case of this program the function is given a 0 which means that it will wait infinite time until a key is pressed.\n",
    "\n",
    "The last function in the cell below simply closes all windows. Execute the cell below, and press any key to destroy the window. You can mouse to coordinates (50,50) on the image and see if it lines up with the BGR value that you saw above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', img) # show the image\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting Images\n",
    "\n",
    "Coverting images to different color schemes is very important to manipulating and isolating important parts of images. Below is a simply color conversion that converts a color image (BGR) to grayscale. It uses the the `cvtColor` function to achieve this which takes the original image as the first paramater and a constant `COLOR_BGR2GRAY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that the cell below is the same as the cell a couple cells above simply with `img` swapped with `gray_image`. Execute it to display the now grayscale image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', gray_image) # show the image\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most important conversions that you will often need to make is the conversion to HSV. HSV stands for \"hue, saturation, value\" and is represented by the graphic below.\n",
    "\n",
    "![hsv](https://www.mathworks.com/help/images/hsvcone.gif)\n",
    "\n",
    "When working with computervision it is often desired to convert images to HSV due to the increased ease in segmenting the color values. Observe the example below.\n",
    "\n",
    "Here we use a new image of a car from behind. The first cell below displays the image in standard BGR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "car_img = cv2.imread('car.jpg')\n",
    "cv2.imshow('image', car_img) # show the image\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, in the cell below, the image is converted to HSV. Notice how the headlights are seperated from the rest of the image. Notice in the `cvtColor` function `COLOR_BGR2HSV` is used as the value for the conversion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "hsv_image = cv2.cvtColor(car_img, cv2.COLOR_BGR2HSV)\n",
    "cv2.imshow('image', hsv_image) # show the image\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Isolate Elements\n",
    "Now that we have converted the image to a more desireable color system, it is time to actually try separating the important elements from the background. To do this we will define a range of values to look for in the image using numpy arrays. In OpenCV, hue ranges from 0 to 179, while saturation and value range from 0 to 255. To isolate important elements we will simply define a range of these values to isolate using OpenCV's `inRange` function and use it as a mask for a `bitwise_and`. Observe the example below with the car image again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = np.array([0,30,0]) # define lower hsv range\n",
    "upper = np.array([10,255,255])# define upper hsv range\n",
    "mask = cv2.inRange(hsv_image, lower, upper)# define a mask using the range\n",
    "        \n",
    "headlights = cv2.bitwise_and(hsv_image, hsv_image, mask=mask) # bitwise and the using the mask\n",
    "\n",
    "cv2.imshow('image', headlights) # show the image\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may notice that something isn't right here. Did we isolate the full range of reds in the image?\n",
    "\n",
    "![car](./car.jpg)\n",
    "\n",
    "Unfortunately we have not isolated all of the red in the image. This is because in HSV red is is not only roughly values 0 to 10 but also values 160 to 179. To account for this we must also use that range to isolate red as well and then add the two ranges together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_1 = np.array([0,30,0]) # define lower hsv range\n",
    "upper_1 = np.array([10,255,255])# define upper hsv range\n",
    "mask_1 = cv2.inRange(hsv_image, lower_1, upper_1)# define a mask using the range\n",
    "\n",
    "lower_2 = np.array([160,0,0]) # define lower hsv range\n",
    "upper_2 = np.array([179,255,255])# define upper hsv range\n",
    "mask_2 = cv2.inRange(hsv_image, lower_2, upper_2)# define a mask using the range\n",
    "        \n",
    "headlights_1 = cv2.bitwise_and(hsv_image, hsv_image, mask=mask_1) # bitwise and the using the mask\n",
    "\n",
    "headlights_2 = cv2.bitwise_and(hsv_image, hsv_image, mask=mask_2)\n",
    "\n",
    "headlights = headlights_1 + headlights_2\n",
    "\n",
    "cv2.imshow('image', headlights) # show the image\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blur\n",
    "The next step is to blur the result from isolating the elements we want. It's very hard to achieve a perfect isolation of the elements that we want, so to improve our isolation we use a blur which effectively averages the isolated section. To blur we must first convert back to BGR using `cvtColor` and `COLOR_HSV2BGR`. Next we use `GaussianBlur` to blur the image. `GaussianBlur` requires us to give four parameters: the first is the image we want to blur, the second is the kernel size which must be positive and odd, and the third and fourth parameters are used for the standard deviation of the gaussian blur (setting them to zero means that we want them to be computed from the kernel size)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "bgr_headlights = cv2.cvtColor(headlights, cv2.COLOR_HSV2BGR)\n",
    "blurred_headlights = cv2.GaussianBlur(bgr_headlights, (5,5), 0, 0)    \n",
    "cv2.imshow('Blurred', blurred_headlights)\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholding\n",
    "Thresholding means to convert the pixels in an image to a consistent color if it is above a certain value and to another color if it is below a certain value. To do thism the `threshold` function is used which requires four parameters: the first is the image that we wish to threshold, the second parameter is the threshold value , the third parameter is the maximum value, and the fourth value is the type of threshold. For this example we are using the simplest thresholding type which is `THRESH_BINARY`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = cv2.threshold(blurred_headlights, 60, 255, cv2.THRESH_BINARY)[1]\n",
    "cv2.imshow('Threshold', thresh)\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detecting Shapes\n",
    "We must now define a function to detect the shapes in the image. To do this we will use something called countours. Contours are simply a list of points that form the edge of a boundary of a shape. The `detect` function defined below takes in a contour as a parameter. \n",
    "\n",
    "To approximate the number of points around a shape we will use two functions. The first, `arcLength`, gets the arc length of the contour. The second function, `approxPolyDP` returns a list of vertices for the approximate polygon. To understand these functions in more detail I encourage you to read up on them using the links below.\n",
    "\n",
    "[cv2.arcLength](https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga8d26483c636be6b35c3ec6335798a47c)\n",
    "\n",
    "[cv2.approxPolyDP](https://docs.opencv.org/3.4/d3/dc0/group__imgproc__shape.html#ga0012a5fdaea70b8a9970165d98722b4c)\n",
    "\n",
    "Then we simply count the number of verticies in the list to determine the shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect(c):\n",
    "        # initialize the shape name and approximate the contour\n",
    "        shape = \"unidentified\"\n",
    "        arc_length = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.06 * arc_length, True)\n",
    "        \n",
    "        # if the shape is a triangle, it will have 3 vertices\n",
    "        if len(approx) == 3:\n",
    "            shape = \"triangle\"\n",
    " \n",
    "        # if the shape has 4 vertices it is a rectangle\n",
    "        elif len(approx) == 4:\n",
    "            shape = \"rectangle\"\n",
    "                 \n",
    "        # if the shape is a pentagon, it will have 5 vertices\n",
    "        elif len(approx) == 5:\n",
    "            shape = \"pentagon\"\n",
    " \n",
    "        # otherwise we will define the shape as a circle\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    " \n",
    "        # return the name of the shape\n",
    "        return (shape, approx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the countours must be found so that they can be input into the `detect` function that we have created. To do this we must first convert our image back to grayscale. Then we can use the `findContours` function to create a list of contours in the image. The first parameter to `findContours` is the grayscale image, the second parameter is `RETR_EXTERNAL` which means that we are only interested in the outermost boundary contours, and the third parameter is our approximation type which we will leave as `CHAIN_APPROX_SIMPLE`.\n",
    "\n",
    "Then we simply enter a for loop which iterates over all of the contours in the image and call our `detect` function on each contour. We then get a value which indicates whether the shape is a rectangle (a headlight). Next we can then draw the contours which outlines the shape and also draw the bounding box around the headlight using the approximate points of the verticies on the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(thresh, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "cnts = cv2.findContours(gray, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)[1]\n",
    "\n",
    "for c in cnts:\n",
    "        \n",
    "    shape, approx = detect(c)\n",
    "\n",
    "\n",
    "    if shape == 'rectangle':\n",
    "        cv2.drawContours(car_img, [c], -1, (0, 255, 0), 1)\n",
    "\n",
    "        (x, y, w, h) = cv2.boundingRect(approx)\n",
    "        cv2.rectangle(car_img,(x,y),(x+w,y+h),(0,255,0),1)\n",
    "        \n",
    "cv2.imshow('Final', car_img)\n",
    "cv2.waitKey(0) # wait until any key is pressed\n",
    "cv2.destroyAllWindows() # destroy all windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
