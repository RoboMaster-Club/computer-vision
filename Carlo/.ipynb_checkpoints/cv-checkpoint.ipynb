{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.4.0'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import argparse\n",
    "import numpy as np\n",
    "import imutils\n",
    "cv2.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Play Video from a File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        cv2.imshow('Frame', frame)\n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Brightest Spot with Gaussian Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        gray = cv2.GaussianBlur(gray, (11,11), 0)\n",
    "        \n",
    "        (minVal, maxVal, minLoc, maxLoc) = cv2.minMaxLoc(gray)\n",
    "        #cv2.circle(frame, minLoc, 5, (255, 0, 0), 2)\n",
    "        cv2.circle(frame, maxLoc, 41, (255, 0, 0), 2)\n",
    "\n",
    "        \n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('Gray', gray)\n",
    "        \n",
    "        \n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Colors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \"\"\"\n",
    "        for (lower, upper) in boundaries:\n",
    "            lower = np.array(lower, dtype='uint8')\n",
    "            upper = np.array(upper, dtype='uint8')\n",
    "            \n",
    "            mask = cv2.inRange(frame, lower, upper)\n",
    "            output = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "        \"\"\"\n",
    "        \n",
    "        #set lower and upper limits in bgr order\n",
    "        lower = np.array([154,147,203], dtype='uint8')\n",
    "        upper = np.array([204,217,255], dtype='uint8')\n",
    "        \n",
    "        mask = cv2.inRange(frame, lower, upper)\n",
    "        output = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "        \n",
    "        #cv2.imshow('Frame', frame)\n",
    "        cv2.imshow(\"images\", np.hstack([frame, output]))\n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Colors with IPython Interact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "\"\"\"\n",
    "#Define the color ranges in BGR order\n",
    "boundaries = [\n",
    "    ([154, 147, 203], [255,255,255]), #Red\n",
    "    ([0, 0, 0], [255, 255, 255]), #Blue\n",
    "    ([0, 0, 0], [255, 255, 255]), #Yellow\n",
    "    ([0, 0, 0], [255, 255, 255]) #Gray\n",
    "]\n",
    "\n",
    "def set_threshold(b, g, r):\n",
    "    return np.array([b,g,r], dtype='uint8')\n",
    "\n",
    "lower = interact(set_threshold, b=154, g=147, r=203)\n",
    "\"\"\"\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \"\"\"\n",
    "        for (lower, upper) in boundaries:\n",
    "            lower = np.array(lower, dtype='uint8')\n",
    "            upper = np.array(upper, dtype='uint8')\n",
    "            \n",
    "            mask = cv2.inRange(frame, lower, upper)\n",
    "            output = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "        \"\"\"\n",
    "        #print(type(lower))\n",
    "        #print(type(interact(set_threshold, b=154, g=147, r=203)))\n",
    "        #lower = set_threshold, b=154, g=147, r=203\n",
    "        #lower = set_threshold(154,147,203)\n",
    "        #upper = set_threshold(204,217,255)\n",
    "        #set lower and upper limits in bgr order\n",
    "        \n",
    "        lower = np.array([154,147,203], dtype='uint8')  \n",
    "        upper = np.array([199,212,250], dtype='uint8')\n",
    "        \n",
    "        mask = cv2.inRange(frame, lower, upper)\n",
    "        output = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "        \n",
    "        #cv2.imshow('Frame', frame)\n",
    "        cv2.imshow(\"images\", np.hstack([frame, output]))\n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-Canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auto_canny(frame, sigma=0.33):\n",
    "    # compute the median of the single channel pixel intensities\n",
    "    v = np.median(frame)\n",
    " \n",
    "    # apply automatic Canny edge detection using the computed median\n",
    "    lower = int(max(0, (1.0 - sigma) * v))\n",
    "    upper = int(min(255, (1.0 + sigma) * v))\n",
    "    edged = cv2.Canny(frame, lower, upper)\n",
    " \n",
    "    # return the edged image\n",
    "    return edged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        \n",
    "        wide = cv2.Canny(blurred, 10, 200)\n",
    "        tight = cv2.Canny(blurred, 280, 300)\n",
    "        auto = auto_canny(blurred)\n",
    " \n",
    "        cv2.imshow('Original', frame)\n",
    "        cv2.imshow('wide', wide)\n",
    "        cv2.imshow('tight', tight)\n",
    "        cv2.imshow('auto', auto)\n",
    "        #cv2.imshow(\"Edges\", np.hstack([wide, tight, auto]))\n",
    "    \n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapeDetector:\n",
    "    def __init__(self):\n",
    "        pass\n",
    " \n",
    "    def detect(self, c):\n",
    "        # initialize the shape name and approximate the contour\n",
    "        shape = \"unidentified\"\n",
    "        peri = cv2.arcLength(c, True)\n",
    "        approx = cv2.approxPolyDP(c, 0.04 * peri, True)\n",
    "        # if the shape is a triangle, it will have 3 vertices\n",
    "        if len(approx) == 3:\n",
    "            shape = \"triangle\"\n",
    " \n",
    "        # if the shape has 4 vertices, it is either a square or\n",
    "        # a rectangle\n",
    "        elif len(approx) == 4:\n",
    "            # compute the bounding box of the contour and use the\n",
    "            # bounding box to compute the aspect ratio\n",
    "            (x, y, w, h) = cv2.boundingRect(approx)\n",
    "            ar = w / float(h)\n",
    " \n",
    "            # a square will have an aspect ratio that is approximately\n",
    "            # equal to one, otherwise, the shape is a rectangle\n",
    "            shape = \"square\" if ar >= 0.95 and ar <= 1.05 else \"rectangle\"\n",
    " \n",
    "        # if the shape is a pentagon, it will have 5 vertices\n",
    "        elif len(approx) == 5:\n",
    "            shape = \"pentagon\"\n",
    " \n",
    "        # otherwise, we assume the shape is a circle\n",
    "        else:\n",
    "            shape = \"circle\"\n",
    " \n",
    "        # return the name of the shape\n",
    "        return shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        resized = imutils.resize(frame, width=3000)\n",
    "        ratio = frame.shape[0] / float(resized.shape[0])\n",
    "        \n",
    "        gray = cv2.cvtColor(resized, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "        thresh = cv2.threshold(blurred, 210, 255, cv2.THRESH_BINARY)[1]\n",
    "        \n",
    "        cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        cnts = cnts[0] if imutils.is_cv2() else cnts[1]\n",
    "        sd = ShapeDetector()\n",
    "        \n",
    "        try:\n",
    "            for c in cnts:\n",
    "                # compute the center of the contour, then detect the name of the\n",
    "                # shape using only the contour\n",
    "                M = cv2.moments(c)\n",
    "                cX = int((M[\"m10\"] / M[\"m00\"]) * ratio)\n",
    "                cY = int((M[\"m01\"] / M[\"m00\"]) * ratio)\n",
    "                shape = sd.detect(c)\n",
    "\n",
    "                # multiply the contour (x, y)-coordinates by the resize ratio,\n",
    "                # then draw the contours and the name of the shape on the image\n",
    "                c = c.astype(\"float\")\n",
    "                c *= ratio\n",
    "                c = c.astype(\"int\")\n",
    "                if shape == 'rectangle':   \n",
    "                    cv2.drawContours(frame, [c], -1, (0, 255, 0), 2)\n",
    "                    cv2.putText(frame, shape, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 255), 2)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        cv2.imshow('Frame', frame)\n",
    "        cv2.imshow('thresh', thresh)\n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture('RedCar.avi')\n",
    "\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret:\n",
    "        \n",
    "        lower = np.array([154,147,203], dtype='uint8')\n",
    "        upper = np.array([174,167,255], dtype='uint8')\n",
    "        \n",
    "        mask = cv2.inRange(frame, lower, upper)\n",
    "        output = cv2.bitwise_and(frame, frame, mask = mask)\n",
    "        \n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        blurred = cv2.GaussianBlur(gray, (3, 3), 0)\n",
    "        \n",
    "        tight_canny = cv2.Canny(output, 280, 300)\n",
    "        \n",
    "        image, contours, hierarchy = cv2.findContours(tight_canny,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        contour_list = []\n",
    "        for contour in contours:\n",
    "            approx = cv2.approxPolyDP(contour,0.01*cv2.arcLength(contour,True),True)\n",
    "            area = cv2.contourArea(contour)\n",
    "            if ((len(approx) > 1) & (area > 1) ):\n",
    "                contour_list.append(contour)\n",
    "        \n",
    "        output = cv2.drawContours(image, contour_list, -1, (255,255,255), 2)\n",
    "        \n",
    "        cv2.imshow('Frame', output)\n",
    "        \n",
    "    if (cv2.waitKey(25) & 0xFF == ord('q')) or not ret:\n",
    "        break\n",
    "        \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture Video from a Camera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print('Error opening video stream or file')\n",
    "\n",
    "while cap.isOpened():\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
